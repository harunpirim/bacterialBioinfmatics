{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"data\\\\training_data.tsv\"\n",
    "hypotheticals_file = \"data\\\\hypothetical_data.tsv\"\n",
    "\n",
    "train_dataset = pd.read_csv(train_file, na_values='?', sep=\"\\t\")\n",
    "hypotheticals_dataset = pd.read_csv(hypotheticals_file, na_values='?', sep=\"\\t\")\n",
    "\n",
    "train_df = train_dataset.copy()\n",
    "hypo_df = hypotheticals_dataset.copy()\n",
    "\n",
    "# Preparing the data\n",
    "train_df = train_df.iloc[:, 2:]  # Remove the first two columns (ID, name)\n",
    "hypo_df = hypo_df.iloc[:, 2:]\n",
    "\n",
    "# Split the data into features and labels\n",
    "X = train_df.iloc[:, :-15]  # Features\n",
    "y = train_df.iloc[:, -15:]  # Labels\n",
    "\n",
    "# Preparing the data for making predictions on hypo_df\n",
    "X_hypo = hypo_df.iloc[:, :-15]  # Features\n",
    "y_hypo = hypo_df.iloc[:, -15:]  # Labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "rf_accuracy = np.mean(cross_val_score(rf_model, X, y, cv=10))\n",
    "\n",
    "print(rf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.fit(X, y)\n",
    "\n",
    "# Make predictions on the new data\n",
    "rf_predictions = rf_model.predict(X_hypo)\n",
    "\n",
    "# Convert the predictions to a DataFrame\n",
    "rf_predictions_df = pd.DataFrame(rf_predictions, columns=y_hypo.columns)\n",
    "\n",
    "# Display the predictions for new proteins\n",
    "print(\"RF Predictions for Hypothetical Proteins:\")\n",
    "print(rf_predictions_df)\n",
    "\n",
    "# Save the DataFrame to the CSV file\n",
    "rf_file = \"rf_predictions.csv\"\n",
    "rf_predictions_df.to_csv(rf_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = MultiOutputClassifier(HistGradientBoostingClassifier(random_state=0))\n",
    "\n",
    "gb_accuracy = np.mean(cross_val_score(gb_model, X, y, cv=10))\n",
    "\n",
    "print(gb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model.fit(X, y)\n",
    "\n",
    "# Make predictions on the new data\n",
    "gb_predictions = gb_model.predict(X_hypo)\n",
    "\n",
    "# Convert the predictions to a DataFrame\n",
    "gb_predictions_df = pd.DataFrame(gb_predictions, columns=y_hypo.columns)\n",
    "\n",
    "# Display the predictions for new proteins\n",
    "print(\"GB Predictions for Hypothetical Proteins:\")\n",
    "print(gb_predictions_df)\n",
    "\n",
    "# Save the DataFrame to the CSV file\n",
    "gb_file = \"gb_predictions.csv\"\n",
    "gb_predictions_df.to_csv(gb_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ISSUE) MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_hypo_scaled = scaler.transform(X_hypo)\n",
    "\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=200, random_state=0)\n",
    "\n",
    "mlp_accuracy = np.mean(cross_val_score(mlp_model, X_scaled, y, cv=10))\n",
    "\n",
    "print(mlp_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model.fit(X, y)\n",
    "\n",
    "# Make predictions on the new data\n",
    "mlp_predictions = mlp_model.predict(X_hypo_scaled)\n",
    "\n",
    "# Convert the predictions to a DataFrame\n",
    "mlp_predictions_df = pd.DataFrame(mlp_predictions, columns=y_hypo.columns)\n",
    "\n",
    "# Display the predictions for new proteins\n",
    "print(\"MLP Predictions for Hypothetical Proteins:\")\n",
    "print(mlp_predictions_df)\n",
    "\n",
    "# Save the DataFrame to the CSV file\n",
    "mlp_file = \"mlp_predictions.csv\"\n",
    "mlp_predictions_df.to_csv(mlp_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
