{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iFeature File Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from Bio import SeqIO\n",
    "\n",
    "#--- iFeature Files [CHANGE BASED ON FILE LOCATION] ---\n",
    "ifeature_files = {\n",
    "\"dpc\" : \"data\\\\train\\\\ifeature\\\\dpc.tsv\",\n",
    "#\"tpc\" : \"data\\\\tpc.tsv\",\n",
    "\"paac\" : \"data\\\\train\\\\ifeature\\\\paac.tsv\",\n",
    "\"ctdc\" : \"data\\\\train\\\\ifeature\\\\ctdc.tsv\",\n",
    "\"ctdt\" : \"data\\\\train\\\\ifeature\\\\ctdt.tsv\",\n",
    "\"ctdd\" : \"data\\\\train\\\\ifeature\\\\ctdd.tsv\",\n",
    "\"ctriad\" : \"data\\\\train\\\\ifeature\\\\ctriad.tsv\",\n",
    "\"gaac\" : \"data\\\\train\\\\ifeature\\\\gaac.tsv\",\n",
    "\"moran\" : \"data\\\\train\\\\ifeature\\\\moran.tsv\"\n",
    "}\n",
    "\n",
    "#--- iFeature output file ---\n",
    "out_file = \"train_iFeature.json\"\n",
    "\n",
    "def nested_dict_to_json(nested_dict, file_path):\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(nested_dict, json_file, indent=4)\n",
    "\n",
    "def json_to_nested_dict(file_path):\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        nested_dict = json.load(json_file)\n",
    "    return nested_dict\n",
    "\n",
    "#--- iFeature cleaning ---\n",
    "def create_dictionary_from_iFeature_tsv(ifeature_file):\n",
    "    dictionary = {}\n",
    "    with open(ifeature_file, 'r') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')\n",
    "        headers = next(reader) \n",
    "        for row in reader:\n",
    "            key = row[0].split(\"|\")[1].strip()  #grabs only protein id\n",
    "            values = {header: value for header, value in zip(headers[1:], row[1:])}\n",
    "            dictionary[key] = values\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "combined_dictionary = {}\n",
    "\n",
    "for key, value in ifeature_files.items():\n",
    "    combined_dictionary[key] = create_dictionary_from_iFeature_tsv(value)\n",
    "\n",
    "nested_dict_to_json(combined_dictionary, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter proteins based on annotion score and completeness of sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from Bio import SeqIO\n",
    "\n",
    "json_raw_file = \"data\\\\train\\\\uniprotkb_taxonomy_id_237_2023_07_09.json\"        #json input file from uniprot download\n",
    "json_filtered_file = \"train_proteins.json\"                                      #json output file for filtered proteins\n",
    "fasta_raw_file = \"data\\\\train\\\\uniprotkb_taxonomy_id_237_2023_07_08.fasta\"      #fasta input file from uniprot download\n",
    "fasta_filtered_file = \"train_proteins.fasta\"                                    #fasta output file for filtered proteins\n",
    "\n",
    "with open(json_raw_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        results = data[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filters out proteins with 1 or 2 annotation score\n",
    "anno_results = []\n",
    "for result in results:\n",
    "    id = result[\"primaryAccession\"]\n",
    "    score = str(result[\"annotationScore\"])\n",
    "    if \"3\" in score or \"4\" in score or \"5\" in score:\n",
    "        anno_results.append(result)\n",
    "    \n",
    "print(len(anno_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filters out proteins with incomplete sequence (sequence contains X)\n",
    "seq_results = []\n",
    "for result in anno_results:\n",
    "    id = result[\"primaryAccession\"]\n",
    "    seq = str(result[\"sequence\"][\"value\"])\n",
    "    if not (\"X\" in seq or \"x\" in seq):\n",
    "        seq_results.append(result)\n",
    "    \n",
    "print(len(seq_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_filtered_file, 'w') as json_file:\n",
    "        json.dump({\"results\" : seq_results}, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_results = seq_results\n",
    "\n",
    "in_fasta_proteins = []\n",
    "for record in SeqIO.parse(fasta_raw_file, \"fasta\"):\n",
    "    in_fasta_proteins.append(record)\n",
    "\n",
    "protein_ids = []\n",
    "for result in json_results:\n",
    "    id = result[\"primaryAccession\"]\n",
    "    protein_ids.append(id)\n",
    "\n",
    "out_fasta_proteins = []\n",
    "for protein in in_fasta_proteins:\n",
    "    for id in protein_ids:\n",
    "        if id in protein.id:\n",
    "            out_fasta_proteins.append(protein)\n",
    "\n",
    "print(len(out_fasta_proteins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fasta_filtered_file, \"w\") as output_handle:\n",
    "    SeqIO.write(out_fasta_proteins, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile protein features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, csv\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "\n",
    "#--- Variables: Training File Locations [CHANGE BASED ON FILE LOCATION] ---\n",
    "train_protein_file = \"train_proteins.fasta\"                #filtered fasta file from above      \n",
    "train_uniprot_file = \"train_proteins.json\"                 #filtered proteins from above\n",
    "train_ifeature_file = \"train_iFeature.json\"                #combined iFeature data from above\n",
    "train_output_file = \"train_protein_information.json\"       #output file for proteins with compile protein features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Functions: Assign Annotations (UniProt) ---\n",
    "def assign_annotations(json_file, proteins):\n",
    "    # Load JSON data from UniProt file\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        results = data[\"results\"]\n",
    "    \n",
    "    for result in results:\n",
    "        id = result[\"primaryAccession\"]\n",
    "        if \"uniProtKBCrossReferences\" in result: proteins[id][\"go_terms\"] = get_go_terms(result)\n",
    "        if \"comments\" in result: proteins[id][\"subcell_locations\"] = get_subcellular_locations(result)\n",
    "        if \"features\" in result: proteins[id][\"transmembrane\"] = get_transmembrane(result)\n",
    "        if \"keywords\" in result: proteins[id][\"binding_preference\"] = get_binding_preference(result)\n",
    "\n",
    "def get_go_terms(protein_info):\n",
    "    go_terms = []\n",
    "    references = protein_info[\"uniProtKBCrossReferences\"]\n",
    "    for reference in references:\n",
    "        if reference[\"database\"] == \"GO\":\n",
    "            go_id = reference[\"id\"]\n",
    "            go_term = reference[\"properties\"][0][\"value\"]\n",
    "            go_terms.append((go_id, go_term))\n",
    "    return go_terms\n",
    "\n",
    "def get_subcellular_locations(protein_info):\n",
    "    subcell_locations = []\n",
    "    comments = protein_info[\"comments\"]\n",
    "    for comment in comments:\n",
    "        if comment[\"commentType\"] == \"SUBCELLULAR LOCATION\":\n",
    "            locations = comment[\"subcellularLocations\"]\n",
    "            for location in locations:\n",
    "                subcell_locations.append(location[\"location\"][\"value\"])\n",
    "    return subcell_locations\n",
    "\n",
    "def get_transmembrane(protein_info):\n",
    "    transmembrane = 0\n",
    "    features = protein_info[\"features\"]\n",
    "    for feature in features:\n",
    "        if feature[\"type\"] == \"Transmembrane\":\n",
    "            transmembrane = 1\n",
    "    return transmembrane\n",
    "\n",
    "def get_binding_preference(protein_info):\n",
    "    bp = []\n",
    "    keywords = protein_info[\"keywords\"]\n",
    "    for keyword in keywords:\n",
    "        kw = keyword[\"name\"]\n",
    "        if (kw == \"DNA-binding\" or kw == \"RNA-binding\"):\n",
    "            bp.append(\"DNA/RNA-binding\")\n",
    "        elif (kw == \"Nucleotide-binding\" or kw == \"Metal-binding\"):\n",
    "            bp.append(kw)\n",
    "    return bp\n",
    "\n",
    "\n",
    "#--- Functions: Assign iFeature Data (iFeature) ---\n",
    "def assign_iFeature_data(ifeature_file, proteins):\n",
    "    with open(ifeature_file, 'r') as file:\n",
    "        features = json.load(file)\n",
    "    for feature, ids in features.items():\n",
    "        for id, value in ids.items():\n",
    "            proteins[id][feature] = value\n",
    "\n",
    "#--- Functions: Assign Protein Names* ---\n",
    "# *names exctracted from EMBL database for test proteins\n",
    "def assign_names(names_file, proteins):\n",
    "    data = []\n",
    "    with open(names_file, 'r') as file:\n",
    "        tsv_reader = csv.reader(file, delimiter='\\t')\n",
    "        next(tsv_reader)\n",
    "        for row in tsv_reader:\n",
    "            data.append(row)\n",
    "    for protein in data:\n",
    "        proteins[protein[0]]['name'] = protein[2]\n",
    "\n",
    "#--- Functions: Generate JSON Based on Dictionary\n",
    "def dict_to_json(dict, file_path):\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Variables: Protein Dictionary ---\n",
    "train_proteins = {}\n",
    "\n",
    "#--- Main: Generate Protein Dictionary ---\n",
    "for record in SeqIO.parse(train_protein_file, \"fasta\"):\n",
    "    protein_id = record.id.split(\"|\")[1].strip()\n",
    "    seq = record.seq\n",
    "    a_seq = ProteinAnalysis(seq)\n",
    "\n",
    "    protein = {\n",
    "        \"seq\" : str(seq),\n",
    "        \"name\" : \"\",\n",
    "        \"length\" : len(record),\n",
    "        \"m_weight\": a_seq.molecular_weight(),\n",
    "        \"instab_index\": a_seq.instability_index(),\n",
    "        \"isoele_point\": a_seq.isoelectric_point(),\n",
    "        \"gravy\": a_seq.gravy(),\n",
    "        \"amino_count\": a_seq.count_amino_acids(),\n",
    "        \"aromaticity\": a_seq.aromaticity(),\n",
    "        \"flexibility\": a_seq.flexibility(),\n",
    "        \"sec_sruct_frac\": a_seq.secondary_structure_fraction(),\n",
    "        \"ext_coeff\": a_seq.molar_extinction_coefficient(),\n",
    "        \"go_terms\": [],\n",
    "        \"dpc\": [],\n",
    "        # \"tpc\": [],\n",
    "        \"paac\": [],\n",
    "        \"ctdc\": [],\n",
    "        \"ctdd\": [],\n",
    "        \"ctdt\": [],\n",
    "        \"ctriad\": [],\n",
    "        \"gaac\": [],\n",
    "        \"moran\": [],\n",
    "        \"subcell_locations\": [],\n",
    "        \"transmembrane\": 0,\n",
    "        \"binding_preference\": [],\n",
    "    }\n",
    "    train_proteins[protein_id] = protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_annotations(train_uniprot_file, train_proteins)\n",
    "assign_iFeature_data(train_ifeature_file, train_proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_json(train_proteins, train_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter for proteins with desired go terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from Bio import SeqIO\n",
    "\n",
    "proteins_json_file = \"train_protein_information.json\"\n",
    "proteins_fasta_file = \"train_proteins.fasta\"\n",
    "\n",
    "with open(proteins_json_file, 'r') as file:\n",
    "    in_json_proteins = json.load(file)\n",
    "\n",
    "in_fasta_proteins = []\n",
    "for record in SeqIO.parse(proteins_fasta_file, \"fasta\"):\n",
    "    in_fasta_proteins.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32822\n",
      "32822\n"
     ]
    }
   ],
   "source": [
    "go_list = [\n",
    "\"GO:0000049\",\n",
    "\"GO:0000287\",\n",
    "\"GO:0003677\",\n",
    "\"GO:0003723\",\n",
    "\"GO:0005506\",\n",
    "\"GO:0005524\",\n",
    "\"GO:0005525\",\n",
    "\"GO:0008270\",\n",
    "\"GO:0016887\",\n",
    "\"GO:0019843\",\n",
    "\"GO:0030170\",\n",
    "\"GO:0046872\",\n",
    "\"GO:0050661\",\n",
    "\"GO:0051287\",\n",
    "\"GO:0051539\",\n",
    "]\n",
    "\n",
    "protein_ids = []\n",
    "selected_ids = []\n",
    "\n",
    "out_json_proteins = {}\n",
    "for id, info in in_json_proteins.items():\n",
    "    protein_ids.append(id)\n",
    "    flag = False\n",
    "    for term in info[\"go_terms\"]:\n",
    "        if term[0] in go_list:\n",
    "            flag = True\n",
    "            selected_ids.append(id)\n",
    "    if flag == True:\n",
    "        out_json_proteins[id] = info\n",
    "    \n",
    "print(len(out_json_proteins))\n",
    "\n",
    "out_fasta_proteins = []\n",
    "for protein in in_fasta_proteins:\n",
    "    if protein.id.split(\"|\")[1].strip() in selected_ids:\n",
    "        out_fasta_proteins.append(protein)\n",
    "\n",
    "print(len(out_fasta_proteins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(proteins_json_file, 'w') as json_file:\n",
    "        json.dump(out_json_proteins, json_file, indent=4)\n",
    "\n",
    "with open(proteins_fasta_file, \"w\") as output_handle:\n",
    "    SeqIO.write(out_fasta_proteins, output_handle, \"fasta\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
